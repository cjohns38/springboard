{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle, gensim, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data \n",
    "\n",
    "data = pickle.load(open('onetsoccode.p', 'rb'))\n",
    "jobtitles = pickle.load(open('lookuptable', 'rb'))\n",
    "\n",
    "# Stop words \n",
    "stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to DF\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df2 = pd.DataFrame(jobtitles).T\n",
    "\n",
    "data = pd.merge(df, \n",
    "                  df2, \n",
    "                  left_on = 'soc', \n",
    "                  right_on = 'soc', \n",
    "                  how = 'left'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to preprocess the text \n",
    "\n",
    "def preprocessText(txt, stopwords): \n",
    "    \"\"\"Use gensim simple preprocess and remove stopwords\"\"\"\n",
    "    stopwords = stopwords\n",
    "    txt = gensim.utils.simple_preprocess(txt)\n",
    "    return  [word for word in txt if word not in stopwords]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "data['processed'] = data.apply(lambda x: preprocessText(x['text'], stopWords), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules & set up logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 20:40:11,820 : INFO : loading projection weights from /home/craig/Documents/googledata/GoogleNews-vectors-negative300.bin\n",
      "2017-11-02 20:41:01,191 : INFO : loaded (3000000, 300) matrix from /home/craig/Documents/googledata/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "# Pretrained vectors from google\n",
    "### https://code.google.com/archive/p/word2vec/\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('/home/craig/Documents/googledata/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create a numpy array of the model word_vec \n",
    "\n",
    "def average_word_embedding(data, model): \n",
    "    \"\"\"Return the average word embedding\"\"\"\n",
    "    out = []\n",
    "    for word in data: \n",
    "        if word in model:\n",
    "            out.append(model.word_vec(word))\n",
    "    # calculate average \n",
    "    avg = np.average(np.array(out), axis = 0)\n",
    "    return pd.Series({'d' + str(idx):x for idx, x in enumerate(avg)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the avg word vectors \n",
    "\n",
    "variables = ['d' + str(x) for x in range(0,300)]\n",
    "data[variables] = data.apply(lambda x: average_word_embedding(x['processed'], word_vectors), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a function that finds the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jobs(data, soc, topN, bottomN): \n",
    "    \"\"\" Given the ONET job DF and a SOC code find the top and bottom similar jobs \"\"\"\n",
    "    \n",
    "    # Create a DF of the target and non-target jobs\n",
    "    target = data[data['soc'] == soc]\n",
    "    df = data[data['soc'] != soc]\n",
    "\n",
    "    # Create target vector \n",
    "    target_vector = data[data['soc'] == soc].loc[:, 'd0':].values[0]\n",
    "    \n",
    "    # Run similarities \n",
    "    s = df.apply(lambda x: cosine_similarity2(target_vector, x), axis = 1)\n",
    "    df = df.assign(similarity = s)\n",
    "    \n",
    "    # Sort the values \n",
    "    df.sort_values(by = 'similarity', ascending = False, inplace = True)\n",
    "    \n",
    "    # Print the top N \n",
    "    top = df[['title', 'similarity']].head(topN).values.tolist()\n",
    "    \n",
    "    # Print the bottom N \n",
    "    bottom = df[['title', 'similarity']].tail(bottomN).values.tolist()\n",
    "    \n",
    "    # Print results \n",
    "    print(\"For the job of {0}...\".format(target['title'].values[0]))\n",
    "    \n",
    "    # Top \n",
    "    print(\"The most similiar jobs are...\".format(target['title'].values[0]))\n",
    "    for job in top: \n",
    "        print(\"\\t {0}\".format(job[0]))\n",
    "    \n",
    "    # Bottom \n",
    "    print(\"The least similar jobs are...\")\n",
    "    for job in bottom: \n",
    "        print('\\t {0}'.format(job[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the job of Singers...\n",
      "The most similiar jobs are...\n",
      "\t Music Directors\n",
      "\t Choreographers\n",
      "\t Public Address System and Other Announcers\n",
      "\t Actors\n",
      "\t Talent Directors\n",
      "The least similar jobs are...\n",
      "\t Methane/Landfill Gas Generation System Technicians\n",
      "\t Green Marketers\n",
      "\t Methane/Landfill Gas Collection System Operators\n",
      "\t Fuel Cell Technicians\n",
      "\t Data Warehousing Specialists\n"
     ]
    }
   ],
   "source": [
    "# Lets look at singers\n",
    "find_jobs(data, '27-2042.01', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the job of Automotive Master Mechanics...\n",
      "The most similiar jobs are...\n",
      "\t Bus and Truck Mechanics and Diesel Engine Specialists\n",
      "\t Automotive Specialty Technicians\n",
      "\t Mobile Heavy Equipment Mechanics, Except Engines\n",
      "\t Outdoor Power Equipment and Other Small Engine Mechanics\n",
      "\t Recreational Vehicle Service Technicians\n",
      "The least similar jobs are...\n",
      "\t Software Developers, Applications\n",
      "\t Green Marketers\n",
      "\t Data Warehousing Specialists\n",
      "\t Investment Underwriters\n",
      "\t Legislators\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at a mechanical job \n",
    "find_jobs(data, '49-3023.01', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the job of Industrial-Organizational Psychologists...\n",
      "The most similiar jobs are...\n",
      "\t Natural Sciences Managers\n",
      "\t Sociologists\n",
      "\t Logisticians\n",
      "\t Social and Community Service Managers\n",
      "\t Counseling Psychologists\n",
      "The least similar jobs are...\n",
      "\t Landscaping and Groundskeeping Workers\n",
      "\t Bakers\n",
      "\t Musical Instrument Repairers and Tuners\n",
      "\t Helpers--Pipelayers, Plumbers, Pipefitters, and Steamfitters\n",
      "\t Agricultural Equipment Operators\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at I/O Psychologist \n",
    "find_jobs(data, '19-3032.00', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the job of Computer Programmers...\n",
      "The most similiar jobs are...\n",
      "\t Software Developers, Applications\n",
      "\t Software Developers, Systems Software\n",
      "\t Software Quality Assurance Engineers and Testers\n",
      "\t Computer Systems Engineers/Architects\n",
      "\t Database Administrators\n",
      "The least similar jobs are...\n",
      "\t Landscaping and Groundskeeping Workers\n",
      "\t Surgeons\n",
      "\t Hunters and Trappers\n",
      "\t Helpers--Pipelayers, Plumbers, Pipefitters, and Steamfitters\n",
      "\t Agricultural Equipment Operators\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at Computer programmers\n",
    "find_jobs(data, '15-1131.00', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the job of Surgeons...\n",
      "The most similiar jobs are...\n",
      "\t Surgical Technologists\n",
      "\t Oral and Maxillofacial Surgeons\n",
      "\t Obstetricians and Gynecologists\n",
      "\t Surgical Assistants\n",
      "\t Veterinarians\n",
      "The least similar jobs are...\n",
      "\t Software Developers, Applications\n",
      "\t Green Marketers\n",
      "\t Investment Underwriters\n",
      "\t Legislators\n",
      "\t Data Warehousing Specialists\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at Computer programmers\n",
    "find_jobs(data, '29-1067.00', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
