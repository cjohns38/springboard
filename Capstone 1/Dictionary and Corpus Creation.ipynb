{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keyring\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up general tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLTK Settings \n",
    "english_stops = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab login and password \n",
    "user = keyring.get_password(\"onet\", \"user\")\n",
    "pw = keyring.get_password(\"onet\", user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB connection string \n",
    "db_uri = 'mysql+pymysql://{user}:{pw}@localhost:3306/onet'.format(user = user, pw = pw)\n",
    "engine = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RIASEC groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createRIASEC(data): \n",
    "    \"\"\" Create a RIASEC st.reset_index(inplace = True)ring\"\"\"\n",
    "    columns = [data['First Interest High-Point'], \n",
    "               data['Second Interest High-Point'], \n",
    "               data['Third Interest High-Point']\n",
    "              ]\n",
    "    \n",
    "    dataOut = [x[0] for x in columns if x != None]\n",
    "    return ''.join(dataOut)\n",
    "\n",
    "def riasecSplit(data): \n",
    "    dataOut = [True  if x in data['riasec'] else False for x in riasecCode]\n",
    "    return pd.Series(dataOut)\n",
    "\n",
    "riasecCode = ['R','I','A','S','E','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qry_riasec = \"\"\"SELECT A.onetsoc_code, B.element_name, C.title, \n",
    "       CASE \n",
    "       WHEN scale_id = 'IH' AND data_value = 1 then 'Realistic'\n",
    "       WHEN scale_id = 'IH' AND data_value = 2 then 'Investigative'\n",
    "       WHEN scale_id = 'IH' AND data_value = 3 then 'Artistic'\n",
    "       WHEN scale_id = 'IH' AND data_value = 4 then 'Social'\n",
    "       WHEN scale_id = 'IH' AND data_value = 5 then 'Enterprising'\n",
    "       WHEN scale_id = 'IH' AND data_value = 6 then 'Conventional'\n",
    "       ELSE '' END AS RIASEC\n",
    "FROM onet.interests as A LEFT JOIN \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "LEFT JOIN onet.occupation_data AS C \n",
    "ON A.onetsoc_code = C.onetsoc_code\n",
    "WHERE scale_id = 'IH' AND data_value != 0\"\"\"\n",
    "\n",
    "# Query the data \n",
    "riasec = pd.read_sql(qry_riasec, engine)\n",
    "\n",
    "# Pivot it to get the top 3 RIASEC where appropriate \n",
    "riasecDF = riasec.pivot(index = 'onetsoc_code', columns = 'element_name', values = 'RIASEC')\n",
    "riasecDF.reset_index(inplace = True)\n",
    "\n",
    "# Create new riasec column\n",
    "riasecDF['riasec'] = riasecDF.apply(lambda x: createRIASEC(x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qry_task = \"\"\"SELECT onetsoc_code, 'Task' as item, task as description, date_updated, domain_source\n",
    "FROM onet.task_statements;\"\"\"\n",
    "\n",
    "qry_toolsTechnology = \"\"\"SELECT onetsoc_code, t2_type as item, Null as date_updated, Null as domain_source, \n",
    "t2_example as description\n",
    "from onet.tools_and_technology\"\"\"\n",
    "\n",
    "qry_knowledge = \"\"\"SELECT A.onetsoc_code, 'Knowledge' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.knowledge as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_skills = \"\"\"SELECT A.onetsoc_code, 'Skills' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.skills as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_abilities = \"\"\"SELECT A.onetsoc_code, 'Abilities' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.abilities as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_workActivities = \"\"\"SELECT A.onetsoc_code, 'WorkActivity' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_activities as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_workContext = \"\"\"SELECT A.onetsoc_code, 'WorkContext' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_context as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'CX' \"\"\"\n",
    "\n",
    "qry_jobzone = \"\"\"SELECT A.onetsoc_code, 'JobZone' as item, A.date_updated, A.domain_source,\n",
    "B.Name as description\n",
    "FROM onet.job_zones as A LEFT JOIN \n",
    "job_zone_reference as B \n",
    "ON A.job_zone = B.job_zone;\"\"\"\n",
    "\n",
    "qry_workStyles = \"\"\"SELECT A.onetsoc_code, 'WorkStyles' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_styles as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_workValues = \"\"\"SELECT A.onetsoc_code, 'WorkValues' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_values as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'EX'\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create individual dataframes \n",
    "tasksDF = pd.read_sql(qry_task, engine)\n",
    "technologySkillsDF = pd.read_sql(qry_toolsTechnology, engine)\n",
    "knowledgeDF = pd.read_sql(qry_knowledge, engine)\n",
    "skillsDF = pd.read_sql(qry_skills, engine)\n",
    "abilitiesDF = pd.read_sql(qry_abilities, engine)\n",
    "workContextDF = pd.read_sql(qry_workContext, engine)\n",
    "jobZoneDF = pd.read_sql(qry_jobzone, engine)\n",
    "workStylesDF = pd.read_sql(qry_workStyles, engine)\n",
    "workValuesDF = pd.read_sql(qry_workValues, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concat them together \n",
    "df = pd.concat([tasksDF, technologySkillsDF, knowledgeDF, skillsDF, abilitiesDF, workContextDF, \n",
    "                jobZoneDF, workStylesDF, workValuesDF\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in riasec\n",
    "df = df.merge(riasecHP[['onetsoc_code', 'riasec']], \n",
    "              left_on = 'onetsoc_code', \n",
    "              right_on = 'onetsoc_code', \n",
    "              how = 'left', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of ONET codes\n",
    "onetsoc_codes = list(df['onetsoc_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Docs  --- MIGHT BE BETTER TO CHANGE THIS SO IT'S NOT ALL IN MEMORY \n",
    "docs=[]\n",
    "for soc in onetsoc_codes: \n",
    "    tmp = {'soc':soc, \n",
    "           'text':' '.join(df[df['onetsoc_code'] == soc]['description'].tolist())\n",
    "          }\n",
    "    docs.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the doc and save it \n",
    "import pickle\n",
    "pickle.dump(docs, open('onetsoccode.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Corpus and Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of documents\n",
    "documents = [doc['text'].lower().split() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-08 13:39:38,095 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-10-08 13:39:38,938 : INFO : built Dictionary(33857 unique tokens: ['resolve', 'customer', 'complaints', 'regarding', 'sales']...) from 974 documents (total 828897 corpus positions)\n",
      "2017-10-08 13:39:38,967 : INFO : saving Dictionary object under onet.dict, separately None\n",
      "2017-10-08 13:39:38,976 : INFO : saved onet.dict\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary \n",
    "dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "# remove stop words and words that appear only once\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in english_stops \n",
    "            if stopword in dictionary.token2id]\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "\n",
    "# remove stop words and words that appear only once\n",
    "dictionary.filter_tokens(stop_ids + once_ids)\n",
    "\n",
    "# Save the dictionary \n",
    "dictionary.save(\"onet.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-08 13:39:39,654 : INFO : storing corpus in Matrix Market format to onet_corpus.mm\n",
      "2017-10-08 13:39:39,655 : INFO : saving sparse matrix to onet_corpus.mm\n",
      "2017-10-08 13:39:39,656 : INFO : PROGRESS: saving document #0\n",
      "2017-10-08 13:39:40,354 : INFO : saved 974x17354 matrix, density=2.710% (457991/16902796)\n",
      "2017-10-08 13:39:40,359 : INFO : saving MmCorpus index to onet_corpus.mm.index\n"
     ]
    }
   ],
   "source": [
    "# Save the corpus \n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "corpora.MmCorpus.serialize('onet_corpus.mm', corpus)  # store to disk, for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a look up table of idx and ONET codes\n",
    "lookup=pd.DataFrame([{'idx':idx, 'soc':x['soc']} for idx, x in enumerate(docs)])\n",
    "\n",
    "riasecDF = riasecDF.merge(lookup, \n",
    "                left_on ='onetsoc_code', \n",
    "                right_on = 'soc',\n",
    "                how = 'left', \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "riasecDF.set_index('idx', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = \"SELECT onetsoc_code, title FROM onet.occupation_data\"\n",
    "jobTitles = riasec = pd.read_sql(titles, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "riasecDF = riasecDF.merge(jobTitles, \n",
    "               left_on = 'onetsoc_code', \n",
    "               right_on = 'onetsoc_code', \n",
    "               how = 'left'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out the raisecDF into a dict\n",
    "pickle.dump(riasecDF.to_dict(orient='index'), open('lookuptable', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
