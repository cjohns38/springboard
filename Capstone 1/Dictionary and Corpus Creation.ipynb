{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keyring\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up general tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLTK Settings \n",
    "english_stops = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab login and password \n",
    "user = keyring.get_password(\"onet\", \"user\")\n",
    "pw = keyring.get_password(\"onet\", user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DB connection string \n",
    "db_uri = 'mysql+pymysql://{user}:{pw}@localhost:3306/onet'.format(user = user, pw = pw)\n",
    "engine = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RIASEC groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createRIASEC(data): \n",
    "    \"\"\" Create a RIASEC st.reset_index(inplace = True)ring\"\"\"\n",
    "    columns = [data['First Interest High-Point'], \n",
    "               data['Second Interest High-Point'], \n",
    "               data['Third Interest High-Point']\n",
    "              ]\n",
    "    \n",
    "    dataOut = [x[0] for x in columns if x != None]\n",
    "    return ''.join(dataOut)\n",
    "\n",
    "def riasecSplit(data): \n",
    "    dataOut = [True  if x in data['riasec'] else False for x in riasecCode]\n",
    "    return pd.Series(dataOut)\n",
    "\n",
    "riasecCode = ['R','I','A','S','E','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qry_riasec = \"\"\"SELECT A.onetsoc_code, B.element_name, C.title, \n",
    "       CASE \n",
    "       WHEN scale_id = 'IH' AND data_value = 1 then 'Realistic'\n",
    "       WHEN scale_id = 'IH' AND data_value = 2 then 'Investigative'\n",
    "       WHEN scale_id = 'IH' AND data_value = 3 then 'Artistic'\n",
    "       WHEN scale_id = 'IH' AND data_value = 4 then 'Social'\n",
    "       WHEN scale_id = 'IH' AND data_value = 5 then 'Enterprising'\n",
    "       WHEN scale_id = 'IH' AND data_value = 6 then 'Conventional'\n",
    "       ELSE '' END AS RIASEC\n",
    "FROM onet.interests as A LEFT JOIN \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "LEFT JOIN onet.occupation_data AS C \n",
    "ON A.onetsoc_code = C.onetsoc_code\n",
    "WHERE scale_id = 'IH' AND data_value != 0\"\"\"\n",
    "\n",
    "# Query the data \n",
    "riasec = pd.read_sql(qry_riasec, engine)\n",
    "\n",
    "# Pivot it to get the top 3 RIASEC where appropriate \n",
    "riasecDF = riasec.pivot(index = 'onetsoc_code', columns = 'element_name', values = 'RIASEC')\n",
    "riasecDF.reset_index(inplace = True)\n",
    "\n",
    "# Create new riasec column\n",
    "riasecDF['riasec'] = riasecDF.apply(lambda x: createRIASEC(x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qry_task = \"\"\"SELECT onetsoc_code, 'Task' as item, task as description, date_updated, domain_source\n",
    "FROM onet.task_statements;\"\"\"\n",
    "\n",
    "qry_toolsTechnology = \"\"\"SELECT onetsoc_code, t2_type as item, Null as date_updated, Null as domain_source, \n",
    "t2_example as description\n",
    "from onet.tools_and_technology\"\"\"\n",
    "\n",
    "qry_knowledge = \"\"\"SELECT A.onetsoc_code, 'Knowledge' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.knowledge as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_skills = \"\"\"SELECT A.onetsoc_code, 'Skills' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.skills as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_abilities = \"\"\"SELECT A.onetsoc_code, 'Abilities' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.abilities as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_workActivities = \"\"\"SELECT A.onetsoc_code, 'WorkActivity' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_activities as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_workContext = \"\"\"SELECT A.onetsoc_code, 'WorkContext' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_context as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'CX' \"\"\"\n",
    "\n",
    "qry_jobzone = \"\"\"SELECT A.onetsoc_code, 'JobZone' as item, A.date_updated, A.domain_source,\n",
    "B.Name as description\n",
    "FROM onet.job_zones as A LEFT JOIN \n",
    "job_zone_reference as B \n",
    "ON A.job_zone = B.job_zone;\"\"\"\n",
    "\n",
    "qry_workStyles = \"\"\"SELECT A.onetsoc_code, 'WorkStyles' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_styles as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'IM' and A.data_value >=3\"\"\"\n",
    "\n",
    "qry_workValues = \"\"\"SELECT A.onetsoc_code, 'WorkValues' as item, A.date_updated, A.domain_source, \n",
    "B.element_name as description\n",
    "FROM onet.work_values as A left join \n",
    "content_model_reference as B \n",
    "ON A.element_id = B.element_id\n",
    "WHERE A.scale_id = 'EX'\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create individual dataframes \n",
    "tasksDF = pd.read_sql(qry_task, engine)\n",
    "technologySkillsDF = pd.read_sql(qry_toolsTechnology, engine)\n",
    "knowledgeDF = pd.read_sql(qry_knowledge, engine)\n",
    "skillsDF = pd.read_sql(qry_skills, engine)\n",
    "abilitiesDF = pd.read_sql(qry_abilities, engine)\n",
    "workContextDF = pd.read_sql(qry_workContext, engine)\n",
    "jobZoneDF = pd.read_sql(qry_jobzone, engine)\n",
    "workStylesDF = pd.read_sql(qry_workStyles, engine)\n",
    "workValuesDF = pd.read_sql(qry_workValues, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concat them together \n",
    "df = pd.concat([tasksDF, technologySkillsDF, knowledgeDF, skillsDF, abilitiesDF, workContextDF, \n",
    "                jobZoneDF, workStylesDF, workValuesDF\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craig/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/craig/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Create a DF with highest interest for each job \n",
    "riasecHP = riasec[riasec['element_name'] == 'First Interest High-Point']\n",
    "riasecHP['riasec'] = riasec.apply(lambda x: x['RIASEC'][0], axis = 1)\n",
    "riasecHP['riasec'] = riasec.apply(lambda x: x['RIASEC'][0], axis = 1)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in riasec\n",
    "df = df.merge(riasecHP[['onetsoc_code', 'riasec']], \n",
    "              left_on = 'onetsoc_code', \n",
    "              right_on = 'onetsoc_code', \n",
    "              how = 'left', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of ONET codes\n",
    "onetsoc_codes = list(df['onetsoc_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Docs  --- MIGHT BE BETTER TO CHANGE THIS SO IT'S NOT ALL IN MEMORY \n",
    "import string \n",
    "\n",
    "docs=[]\n",
    "for soc in onetsoc_codes: \n",
    "    text = ' '.join(df[df['onetsoc_code'] == soc]['description'].tolist())\n",
    "    out = text.translate(text.maketrans(\"\",\"\", string.punctuation))\n",
    "\n",
    "    tmp = {'soc': soc, \n",
    "           'text': out\n",
    "          }\n",
    "    docs.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the doc and save it \n",
    "import pickle\n",
    "pickle.dump(docs, open('onetsoccode.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Corpus and Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a list of documents\n",
    "documents = [doc['text'].lower().split() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-15 21:37:25,332 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-10-15 21:37:26,160 : INFO : built Dictionary(25292 unique tokens: ['resolve', 'customer', 'complaints', 'regarding', 'sales']...) from 974 documents (total 828830 corpus positions)\n",
      "2017-10-15 21:37:26,186 : INFO : saving Dictionary object under onet.dict, separately None\n",
      "2017-10-15 21:37:26,196 : INFO : saved onet.dict\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary \n",
    "dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "# remove stop words and words that appear only once\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in english_stops \n",
    "            if stopword in dictionary.token2id]\n",
    "\n",
    "# remove stop words and words that appear only once\n",
    "dictionary.filter_tokens(stop_ids)\n",
    "\n",
    "# Save the dictionary \n",
    "dictionary.save(\"onet.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-15 21:37:26,902 : INFO : storing corpus in Matrix Market format to onet_corpus.mm\n",
      "2017-10-15 21:37:26,904 : INFO : saving sparse matrix to onet_corpus.mm\n",
      "2017-10-15 21:37:26,905 : INFO : PROGRESS: saving document #0\n",
      "2017-10-15 21:37:27,605 : INFO : saved 974x25184 matrix, density=1.842% (451904/24529216)\n",
      "2017-10-15 21:37:27,608 : INFO : saving MmCorpus index to onet_corpus.mm.index\n"
     ]
    }
   ],
   "source": [
    "# Save the corpus \n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "corpora.MmCorpus.serialize('onet_corpus.mm', corpus)  # store to disk, for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a look up table of idx and ONET codes\n",
    "lookup=pd.DataFrame([{'idx':idx, 'soc':x['soc']} for idx, x in enumerate(docs)])\n",
    "\n",
    "riasecDF = riasecDF.merge(lookup, \n",
    "                left_on ='onetsoc_code', \n",
    "                right_on = 'soc',\n",
    "                how = 'left', \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riasecDF.set_index('idx', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = \"SELECT onetsoc_code, title FROM onet.occupation_data\"\n",
    "jobTitles = riasec = pd.read_sql(titles, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riasecDF = riasecDF.merge(jobTitles, \n",
    "               left_on = 'onetsoc_code', \n",
    "               right_on = 'onetsoc_code', \n",
    "               how = 'left'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save out the raisecDF into a dict\n",
    "pickle.dump(riasecDF.to_dict(orient='index'), open('lookuptable', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
